{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZj0HQZozH/AF6R4+zzB4U"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EudQ5lMINnh4",
        "outputId": "3c8b8af5-397b-4474-8765-4a1dd1e1da9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efwlqWPlqnAq",
        "outputId": "da37c9f9-785a-4954-85b3-7a6dba51d58e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1563/1563 [==============================] - 149s 95ms/step - loss: 1.8770 - accuracy: 0.3261\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import keras.utils as utils\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers.convolutional import Conv2D , MaxPooling2D\n",
        "from keras.constraints import maxnorm\n",
        "import numpy as np\n",
        "from keras.datasets import cifar10\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "labels =[\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "y_train = utils.to_categorical(y_train)\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "y_test = utils.to_categorical(y_test)\n",
        "\n",
        "\n",
        "\n",
        "# Create the model as a sequential type so that we can add layers in order\n",
        "model = Sequential()\n",
        "#Add the first convolution to output a feature map.\n",
        "#filters: output 32 features\n",
        "#Kernel_sizes: 3X3 kernel or filter matrix used to calculate output features\n",
        "#input_shapes: each image 32x32x3\n",
        "#activation: relu activation for each of the operation asit produces the best results\n",
        "#padding: 'same' adds padding to the input image to make sure that the output feature map is the same size as the input\n",
        "#kernel_constraint: maxnorm normalises the values in the kernel to make sure that the max value is 3. \n",
        "model.add(Conv2D(filters=32,kernel_size=(5,5),input_shape=(32,32,3),activation='relu', padding='same',\n",
        "                 kernel_constraint=maxnorm(3)))\n",
        "#Add the max pool layer to decrese the image size from 32x32 to 16x16\n",
        "#pool_size: finds the max value in each 2x2 section of the input\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#Flatten layer converts a matrix into one dimensional array\n",
        "model.add(Flatten())\n",
        "#First dense layer to create the actual preditcion network\n",
        "#units: 512 neurons at this layer, increase for freater accuracy, decrease for faster train speed\n",
        "#activation: relu also because it works well\n",
        "#kernel_constraint: same as the above\n",
        "model.add(Dense(units=512,activation='relu', kernel_constraint=maxnorm(3)))\n",
        "#Droput_layer to ignore some neurons training which improves model reliability\n",
        "#rate: 0.5 means half neurins dropped\n",
        "model.add(Dropout(rate=0.5))\n",
        "# Final dense layer used to prouduce output for each of the 10 categories\n",
        "#units: 10 categories so 10 output units.\n",
        "# activation: softmax because we are calculating probabilities probabilities for each of the 10 categories\n",
        "#(not as clear as 0 or 1)\n",
        "model.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=SGD(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x=x_train,y=y_train,epochs=35, batch_size=32)\n",
        "\n",
        "model.save(filepath='/content/drive/MyDrive/Cifar-10 dataset/Image_classifier.h5')\n",
        "\n",
        "\n"
      ]
    }
  ]
}