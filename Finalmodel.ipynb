{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNea1RDW2EoNzZ6NP5FJlQJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jsuryaboi-08/object-detection-with-keras-api-using-python/blob/main/Finalmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EudQ5lMINnh4",
        "outputId": "7a824ac3-efc4-46b4-e515-0a22fd7cbbd1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efwlqWPlqnAq",
        "outputId": "70e44e9d-af17-4d6a-9232-373c37f10365"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 161s 102ms/step - loss: 2.0113 - accuracy: 0.2654\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 162s 104ms/step - loss: 1.6534 - accuracy: 0.4038\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 162s 104ms/step - loss: 1.4985 - accuracy: 0.4601\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 160s 102ms/step - loss: 1.3913 - accuracy: 0.5012\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 162s 104ms/step - loss: 1.3046 - accuracy: 0.5329\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import keras.utils as utils\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers.convolutional import Conv2D , MaxPooling2D\n",
        "from keras.constraints import maxnorm\n",
        "import numpy as np\n",
        "from keras.datasets import cifar10\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "labels =[\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "y_train = utils.to_categorical(y_train)\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "y_test = utils.to_categorical(y_test)\n",
        "\n",
        "\n",
        "\n",
        "# Create the model as a sequential type so that we can add layers in order\n",
        "model = Sequential()\n",
        "#Add the first convolution to output a feature map.\n",
        "#filters: output 32 features\n",
        "#Kernel_sizes: 3X3 kernel or filter matrix used to calculate output features\n",
        "#input_shapes: each image 32x32x3\n",
        "#activation: relu activation for each of the operation asit produces the best results\n",
        "#padding: 'same' adds padding to the input image to make sure that the output feature map is the same size as the input\n",
        "#kernel_constraint: maxnorm normalises the values in the kernel to make sure that the max value is 3.\n",
        "model.add(Conv2D(filters=32,kernel_size=(5,5),input_shape=(32,32,3),activation='relu', padding='same',\n",
        "                 kernel_constraint=maxnorm(3)))\n",
        "#Add the max pool layer to decrese the image size from 32x32 to 16x16\n",
        "#pool_size: finds the max value in each 2x2 section of the input\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#adddition of two more layers\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#Flatten layer converts a matrix into one dimensional array\n",
        "model.add(Flatten())\n",
        "#First dense layer to create the actual preditcion network\n",
        "#units: 512 neurons at this layer, increase for freater accuracy, decrease for faster train speed\n",
        "#activation: relu also because it works well\n",
        "#kernel_constraint: same as the above\n",
        "model.add(Dense(units=512,activation='relu', kernel_constraint=maxnorm(3)))\n",
        "#Droput_layer to ignore some neurons training which improves model reliability\n",
        "#rate: 0.5 means half neurins dropped\n",
        "model.add(Dropout(rate=0.5))\n",
        "# Final dense layer used to prouduce output for each of the 10 categories\n",
        "#units: 10 categories so 10 output units.\n",
        "# activation: softmax because we are calculating probabilities probabilities for each of the 10 categories\n",
        "#(not as clear as 0 or 1)\n",
        "model.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=SGD(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x=x_train,y=y_train,epochs=35, batch_size=32)\n",
        "\n",
        "model.save(filepath='/content/drive/MyDrive/Cifar-10 dataset/Image_classifier.h5')\n",
        "\n",
        "\n"
      ]
    }
  ]
}